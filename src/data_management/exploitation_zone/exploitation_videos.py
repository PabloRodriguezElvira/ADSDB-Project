import hashlib
import time
import tempfile
from typing import List
import numpy as np
import cv2
from minio.error import S3Error

from src.common.minio_client import get_minio_client
from src.common.chroma_client import get_client, get_video_collection
import src.common.global_variables as config
from src.common.progress_bar import ProgressBar


def _hash_text(s: str, n: int = 16) -> str:
    """Return a short SHA-256 hash for a given string."""
    return hashlib.sha256(s.encode("utf-8")).hexdigest()[:n]


def list_objects(client, bucket, prefix) -> List:
    """List all object files from a MinIO bucket and prefix."""
    return [
        obj for obj in client.list_objects(bucket, prefix=prefix, recursive=True)
        if not obj.object_name.endswith("/")
    ]


def extract_frames_from_file(path: str, frame_interval_s: float = 1.0, max_frames: int = 100):
    """
    Generator that extracts frames from a video file.

    Yields (frame_index, timestamp_seconds, frame_bgr) every `frame_interval_s` seconds,
    up to a maximum of `max_frames` frames.
    """
    cap = cv2.VideoCapture(path)
    if not cap.isOpened():
        return

    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
    duration_s = total_frames / fps if fps > 0 else 0

    step_frames = max(1, int(round(frame_interval_s * fps)))
    frame_idx = 0
    yielded = 0

    # Iterate through frames and yield periodically
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if frame_idx % step_frames == 0:
            timestamp_s = frame_idx / fps if fps > 0 else 0.0
            yield yielded, timestamp_s, frame  # BGR frame
            yielded += 1
            if yielded >= max_frames:
                break
        frame_idx += 1

    cap.release()


def ingest_trusted_videos(
    frame_interval_s: float = 1.0,
    max_frames_per_video: int = 50,
    batch_size: int = 64,
):
    """
    Ingest frames from videos stored in the trusted MinIO bucket into Chroma.

    Steps:
      1. Download each video temporarily from MinIO.
      2. Extract frames every `frame_interval_s` seconds.
      3. Convert frames to RGB and store as NumPy arrays.
      4. Batch insert frames and metadata into Chroma.
    """
    # Initialize clients
    s3 = get_minio_client()
    cli = get_client()
    col = get_video_collection(cli)

    # List all trusted videos 
    objects = list_objects(s3, config.TRUSTED_BUCKET, config.TRUSTED_VIDEO_PATH)
    total_objects = len(objects)
    if total_objects == 0:
        print(f"[WARN] No trusted videos found at {config.TRUSTED_VIDEO_PATH}.")
        return 0
    print(f"Processing {total_objects} videos from {config.TRUSTED_VIDEO_PATH}...")

    ids, imgs_np, metas = [], [], []
    total = 0
    now = int(time.time())

    # Progress bar for visual feedback
    with ProgressBar(
        total=total_objects,
        description="Ingesting videos",
        unit="video",
        unit_scale=False,
    ) as progress:
        for obj in objects:
            progress.set_description(f"Ingesting {obj.object_name}", refresh=False)
            try:
                # Download video temporarily 
                s3obj = s3.get_object(config.TRUSTED_BUCKET, obj.object_name)
                with tempfile.NamedTemporaryFile(suffix=".mp4", delete=True) as tmp:
                    for chunk in s3obj.stream(32 * 1024):
                        tmp.write(chunk)
                    tmp.flush()
                    s3obj.close()
                    s3obj.release_conn()

                    # Extract frames 
                    for frame_idx, timestamp_s, frame_bgr in extract_frames_from_file(
                        tmp.name, frame_interval_s=frame_interval_s, max_frames=max_frames_per_video
                    ):
                        # Convert to RGB and prepare metadata 
                        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
                        arr = np.asarray(frame_rgb, dtype=np.uint8)

                        fid = _hash_text(f"{obj.object_name}::{frame_idx}::{int(timestamp_s*1000)}")
                        ids.append(fid)
                        imgs_np.append(arr)
                        metas.append({
                            "video_key": obj.object_name,
                            "frame_idx": frame_idx,
                            "timestamp_s": float(timestamp_s),
                            "file_hash": fid,
                            "size_bytes": tmp.tell(),
                            "created_at": now,
                        })

                        # Batch insert frames into Chroma 
                        if len(ids) >= batch_size:
                            col.add(ids=ids, images=imgs_np, metadatas=metas)
                            total += len(ids)
                            ids.clear()
                            imgs_np.clear()
                            metas.clear()

            except S3Error as e:
                progress.write(f"SKIP (MinIO): {obj.object_name} ({e})")
            except Exception as e:
                progress.write(f"ERROR processing {obj.object_name}: {e}")
            finally:
                progress.update(1)

    # Final flush for remaining frames
    if ids:
        col.add(ids=ids, images=imgs_np, metadatas=metas)
        total += len(ids)

    print(f"\nOK - Frames ingested into Chroma: {total}")
    return total


if __name__ == "__main__":
    # Run ingestion with default parameters
    ingest_trusted_videos(
        frame_interval_s=1.0,     # extract 1 frame per second
        max_frames_per_video=60,  # limit frames per video
        batch_size=128,           # number of frames per insertion batch
    )
