import hashlib
import time
import tempfile
from typing import List
import numpy as np
import cv2
from minio.error import S3Error

from src.common.minio_client import get_minio_client
from src.common.chroma_client import get_client, get_video_collection, _text_image_ef
import src.common.global_variables as config
from src.common.progress_bar import ProgressBar


def _hash_text(s: str, n: int = 16):
    """Return a short SHA-256 hash for a given string."""
    return hashlib.sha256(s.encode("utf-8")).hexdigest()[:n]


def list_objects(client, bucket, prefix):
    """List all object files from a MinIO bucket and prefix."""
    return [
        obj for obj in client.list_objects(bucket, prefix=prefix, recursive=True)
        if not obj.object_name.endswith("/")
    ]


def extract_frames_from_file(path: str, frame_interval_s: float = 1.0, max_frames: int = 100):
    """
    Generator that extracts frames from a video file.

    Yields (frame_index, timestamp_seconds, frame_bgr) every `frame_interval_s` seconds,
    up to a maximum of `max_frames` frames.
    """
    cap = cv2.VideoCapture(path)
    if not cap.isOpened():
        return

    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
    duration_s = total_frames / fps if fps > 0 else 0

    step_frames = max(1, int(round(frame_interval_s * fps)))
    frame_idx = 0
    yielded = 0

    # Iterate through frames and yield periodically
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if frame_idx % step_frames == 0:
            timestamp_s = frame_idx / fps if fps > 0 else 0.0
            yield yielded, timestamp_s, frame  # BGR frame
            yielded += 1
            if yielded >= max_frames:
                break
        frame_idx += 1

    cap.release()


def _compute_average_embedding(frame_arrays: List[np.ndarray]):
    """Return the average embedding vector for the provided list of RGB frames."""
    if not frame_arrays:
        raise ValueError("No frames available to compute the embedding.")

    embeddings = _text_image_ef(frame_arrays)
    if not embeddings:
        raise ValueError("The embedding function returned no embeddings.")

    embeddings_np = np.asarray(embeddings, dtype=np.float32)
    return embeddings_np.mean(axis=0).tolist()


def ingest_trusted_videos(
    frame_interval_s: float = 1.0,
    max_frames_per_video: int = 50,
    batch_size: int = 64,
):
    """
    Ingest trusted videos by computing a single embedding per video.

    Steps:
      1. Download each video temporarily from MinIO.
      2. Extract frames every `frame_interval_s` seconds.
      3. Obtain embeddings for all sampled frames and average them.
      4. Store the resulting per-video embedding and metadata in Chroma.
    """
    s3 = get_minio_client()
    cli = get_client()
    col = get_video_collection(cli)

    objects = list_objects(s3, config.TRUSTED_BUCKET, config.TRUSTED_VIDEO_PATH)
    total_objects = len(objects)
    if total_objects == 0:
        print(f"[WARN] No trusted videos found at {config.TRUSTED_VIDEO_PATH}.")
        return 0
    print(f"Processing {total_objects} videos from {config.TRUSTED_VIDEO_PATH}...")

    ids, embeddings, metas = [], [], []
    total = 0
    now = int(time.time())

    with ProgressBar(
        total=total_objects,
        description="Ingesting videos",
        unit="video",
        unit_scale=False,
    ) as progress:
        for obj in objects:
            progress.set_description(f"Ingesting {obj.object_name}", refresh=False)
            try:
                s3obj = s3.get_object(config.TRUSTED_BUCKET, obj.object_name)
                with tempfile.NamedTemporaryFile(suffix=".mp4", delete=True) as tmp:
                    for chunk in s3obj.stream(32 * 1024):
                        tmp.write(chunk)
                    tmp.flush()
                    s3obj.close()
                    s3obj.release_conn()

                    # Gather all sampled frames for the current video.
                    frame_arrays: List[np.ndarray] = []
                    frame_count = 0
                    for _, _, frame_bgr in extract_frames_from_file(
                        tmp.name,
                        frame_interval_s=frame_interval_s,
                        max_frames=max_frames_per_video,
                    ):
                        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
                        arr = np.asarray(frame_rgb, dtype=np.uint8)
                        frame_arrays.append(arr)
                        frame_count += 1

                    if not frame_arrays:
                        progress.write(f"SKIP (no frames): {obj.object_name}")
                        continue

                    try:
                        # Average embeddings so each video is represented by one vector.
                        video_embedding = _compute_average_embedding(frame_arrays)
                    except ValueError as exc:
                        progress.write(f"SKIP (embedding): {obj.object_name} ({exc})")
                        continue

                    video_id = _hash_text(f"{obj.object_name}::{now}")
                    ids.append(video_id)
                    embeddings.append(video_embedding)
                    metas.append(
                        {
                            "video_key": obj.object_name,
                            "frame_count": frame_count,
                            "frame_interval_s": frame_interval_s,
                            "size_bytes": tmp.tell(),
                            "created_at": now,
                        }
                    )

                    # Insert in batches to avoid large payloads when many videos are processed.
                    if len(ids) >= batch_size:
                        col.add(ids=ids, embeddings=embeddings, metadatas=metas)
                        total += len(ids)
                        ids.clear()
                        embeddings.clear()
                        metas.clear()

            except S3Error as e:
                progress.write(f"SKIP (MinIO): {obj.object_name} ({e})")
            except Exception as e:
                progress.write(f"ERROR processing {obj.object_name}: {e}")
            finally:
                progress.update(1)

    if ids:
        col.add(ids=ids, embeddings=embeddings, metadatas=metas)
        total += len(ids)

    print(f"\nOK - Videos ingested into Chroma: {total}")
    return total


if __name__ == "__main__":
    # Run ingestion with default parameters
    ingest_trusted_videos(
        frame_interval_s=1.0,     # extract 1 frame per second
        max_frames_per_video=60,  # limit frames per video
        batch_size=128,           # number of videos per insertion batch
    )
